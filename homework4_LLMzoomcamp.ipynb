{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OCmLOLkLh6qt",
        "outputId": "5c8e3d79-7802-4747-a3c8-a5dac2991115"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Aug  4 07:14:18 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   72C    P0              30W /  70W |    657MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "QwUGCR45TtKA"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence-transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BCCUpqDIQWPs",
        "outputId": "43091649-d23b-4f28-9d70-7383b83ad351"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (3.0.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.42.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.4)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.3.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.26.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.3.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.23.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.15.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2024.6.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence-transformers) (12.6.20)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2024.5.15)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.4.3)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.19.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.7.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "model_name = \"multi-qa-mpnet-base-dot-v1\"\n",
        "embedding_model = SentenceTransformer(model_name)\n"
      ],
      "metadata": {
        "id": "7ZiYbsTEPs2T"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "OPnKyjVSA_07"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "github_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main/04-monitoring/data/results-gpt4o-mini.csv'\n",
        "url = f'{github_url}?raw=1'\n",
        "\n",
        "# Read the dataset\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "# Use only the first 300 documents\n",
        "df = df.iloc[:300]"
      ],
      "metadata": {
        "id": "--AMRME5A6ip"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vdrp1LoTQnSD",
        "outputId": "cd616667-e7d8-4c28-bb3a-fdf4ca568651"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['answer_llm', 'answer_orig', 'document', 'question', 'course'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "answer_llm = df.iloc[0].answer_llm\n",
        "embeddings = embedding_model.encode(answer_llm)"
      ],
      "metadata": {
        "id": "fFOKz7imP50P"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(embeddings[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RcdGWSUjTJ2H",
        "outputId": "967274d7-c0d6-405d-a341-2195067d4310"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-0.42244664\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What's the first value of the resulting vector?\n",
        "\n",
        "**-0.42**\n",
        "-0.22\n",
        "-0.02\n",
        "0.21"
      ],
      "metadata": {
        "id": "eGvP-MmBTPM3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "evaluations = []\n",
        "for index, row in df.iterrows():\n",
        "    answer_llm = row['answer_llm']\n",
        "    answer_orig = row['answer_orig']\n",
        "\n",
        "    embedding_llm = embedding_model.encode(answer_llm)\n",
        "    embedding_orig = embedding_model.encode(answer_orig)\n",
        "\n",
        "    cosine_similarity = np.dot(embedding_llm, embedding_orig)\n",
        "\n",
        "    evaluations.append(cosine_similarity)\n",
        "\n",
        "# Calculate the 75th percentile of the cosine similarities\n",
        "percentile_75 = np.percentile(evaluations, 75)\n",
        "\n",
        "# Print the 75th percentile\n",
        "print(f\"The 75th percentile of the cosine similarities is: {percentile_75}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHnboZL8Tcia",
        "outputId": "1d9e64d2-39f7-436f-926d-2911e8813d08"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The 75th percentile of the cosine similarities is: 31.674304962158203\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What's the 75% percentile of the score?\n",
        "\n",
        "21.67\n",
        "**31.67**\n",
        "41.67\n",
        "51.67\n",
        "\n",
        "Answer:** 31.67**"
      ],
      "metadata": {
        "id": "tRXYx-VqT6t_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize(v):\n",
        "    norm = np.sqrt((v * v).sum())\n",
        "    return v / norm"
      ],
      "metadata": {
        "id": "uwTYghnqVJrW"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Initialize an empty list to store the cosine similarity scores\n",
        "evaluations = []\n",
        "\n",
        "# Iterate over each row in the DataFrame\n",
        "for index, row in df.iterrows():\n",
        "    answer_llm = row['answer_llm']\n",
        "    answer_orig = row['answer_orig']\n",
        "\n",
        "    # Create embeddings for both answers using the embedding model\n",
        "    embedding_llm = embedding_model.encode(answer_llm)\n",
        "    embedding_orig = embedding_model.encode(answer_orig)\n",
        "\n",
        "    # Normalize the embeddings to ensure they have a unit length\n",
        "    embedding_llm_norm = embedding_llm / np.linalg.norm(embedding_llm)\n",
        "    embedding_orig_norm = embedding_orig / np.linalg.norm(embedding_orig)\n",
        "\n",
        "    # Compute the dot product (cosine similarity) between the normalized embeddings\n",
        "    cosine_similarity = np.dot(embedding_llm_norm, embedding_orig_norm)\n",
        "\n",
        "    # Append the result to the evaluations list\n",
        "    evaluations.append(cosine_similarity)\n",
        "\n",
        "# Calculate the 75th percentile of the cosine similarities\n",
        "percentile_75 = np.percentile(evaluations, 75)\n",
        "\n",
        "# Print the 75th percentile\n",
        "print(f\"The 75th percentile of the cosine similarities is: {percentile_75}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-FMT2hLUq08",
        "outputId": "b09c3d51-f0fe-4b0c-dd4c-4d184f12c833"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The 75th percentile of the cosine similarities is: 0.8362347185611725\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What's the 75% cosine in the scores?\n",
        "\n",
        "0.63\n",
        "0.73\n",
        "**0.83**\n",
        "0.93\n",
        "\n",
        "Answer: **0.83**"
      ],
      "metadata": {
        "id": "UJz8CtljUVkP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "viIZTCD-Tl3G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install rouge"
      ],
      "metadata": {
        "id": "c1gu5i4zmrdk"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rouge-score\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HB05NRCanC2i",
        "outputId": "a9180e93-00a7-4863-fa15-a91802232db3"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rouge-score in /usr/local/lib/python3.10/dist-packages (0.1.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge-score) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.26.4)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (4.66.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the necessary package\n",
        "# !pip install rouge-score\n",
        "\n",
        "# Import the necessary libraries\n",
        "import pandas as pd\n",
        "from rouge_score import rouge_scorer\n",
        "\n",
        "\n",
        "github_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main/04-monitoring/data/results-gpt4o-mini.csv'\n",
        "url = f'{github_url}?raw=1'\n",
        "df = pd.read_csv(url)\n",
        "df = df.iloc[:300]\n",
        "rouge_scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "r = df.iloc[10]\n",
        "scores = rouge_scorer.score(r['answer_llm'], r['answer_orig'])\n",
        "print(f\"The F1 score for ROUGE-1 is: {scores['rouge1'].fmeasure}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t277blcYu0Rt",
        "outputId": "6414c005-6146-4f7c-c5fc-00160f39eece"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The F1 score for ROUGE-1 is: 0.5063291139240506\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from rouge_score import rouge_scorer\n",
        "\n",
        "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "\n",
        "r = df.iloc[10]\n",
        "answer_llm = r['answer_llm']\n",
        "answer_orig = r['answer_orig']"
      ],
      "metadata": {
        "id": "rCyMxV94vgsr"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores = scorer.score(answer_llm, answer_orig)\n",
        "rouge_1_f1 = scores['rouge1'].fmeasure\n",
        "print(f\"F1 score for rouge-1: {rouge_1_f1}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7uSfY-lvj5H",
        "outputId": "f8df0c26-49de-4c87-fef6-d64f9691bac4"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 score for rouge-1: 0.5063291139240506\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from rouge_score import rouge_scorer\n",
        "\n",
        "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "\n",
        "r = df.iloc[10]\n",
        "answer_llm = r['answer_llm']\n",
        "answer_orig = r['answer_orig']\n",
        "\n",
        "scores = scorer.score(answer_llm, answer_orig)\n",
        "\n",
        "rouge_1_f = scores['rouge1'].fmeasure\n",
        "rouge_2_f = scores['rouge2'].fmeasure\n",
        "rouge_l_f = scores['rougeL'].fmeasure\n",
        "\n",
        "average_f_score = (rouge_1_f + rouge_2_f + rouge_l_f) / 3\n",
        "\n",
        "print(f\"Rouge-1 F-score: {rouge_1_f}\")\n",
        "print(f\"Rouge-2 F-score: {rouge_2_f}\")\n",
        "print(f\"Rouge-L F-score: {rouge_l_f}\")\n",
        "print(f\"Average F-score: {average_f_score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-O9K2iZvyOc",
        "outputId": "4f81b6bc-98dd-43e4-8ccd-92b7e93aa80d"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rouge-1 F-score: 0.5063291139240506\n",
            "Rouge-2 F-score: 0.3116883116883117\n",
            "Rouge-L F-score: 0.37974683544303806\n",
            "Average F-score: 0.3992547536851334\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "\n",
        "rouge_1_f = []\n",
        "rouge_2_f = []\n",
        "rouge_l_f = []\n",
        "\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "    scores = scorer.score(row['answer_llm'], row['answer_orig'])\n",
        "    rouge_1_f.append(scores['rouge1'].fmeasure)\n",
        "    rouge_2_f.append(scores['rouge2'].fmeasure)\n",
        "    rouge_l_f.append(scores['rougeL'].fmeasure)\n",
        "\n",
        "\n",
        "rouge_scores_df = pd.DataFrame({\n",
        "    'rouge-1_f': rouge_1_f,\n",
        "    'rouge-2_f': rouge_2_f,\n",
        "    'rouge-l_f': rouge_l_f\n",
        "})\n",
        "\n",
        "\n",
        "average_rouge_2 = rouge_scores_df['rouge-2_f'].mean()\n",
        "\n",
        "print(f\"The average ROUGE-2 score across all records is: {average_rouge_2}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QD5TONVIytQ2",
        "outputId": "b742e36f-f835-4526-9046-f1529f05c616"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The average ROUGE-2 score across all records is: 0.2880237296538236\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "!{sys.executable} -m pip install rouge\n",
        "from rouge import Rouge"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFsfGOiU2vtz",
        "outputId": "4dc3f7b5-a74c-4fcf-d499-34c23f249290"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rouge in /usr/local/lib/python3.10/dist-packages (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from rouge) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from rouge import Rouge\n",
        "\n",
        "# URL of the dataset\n",
        "github_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main/04-monitoring/data/results-gpt4o-mini.csv'\n",
        "url = f'{github_url}?raw=1'\n",
        "\n",
        "# Read the dataset\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "# Use only the first 300 documents\n",
        "df = df.iloc[:300]\n",
        "\n",
        "# Initialize the ROUGE scorer\n",
        "rouge_scorer = Rouge()\n",
        "\n",
        "# Get the answers at index 10\n",
        "r = df.iloc[10]\n",
        "\n",
        "# Compute the ROUGE scores\n",
        "scores = rouge_scorer.get_scores(r['answer_llm'], r['answer_orig'])[0]\n",
        "\n",
        "# Print the F1 score for ROUGE-1\n",
        "print(f\"The F1 score for ROUGE-1 is: {scores['rouge-1']['f']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6sVubhG2-xx",
        "outputId": "b740523e-151a-494d-8a72-28255913b117"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The F1 score for ROUGE-1 is: 0.45454544954545456\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What's the F score for rouge-1?\n",
        "\n",
        "0.35\n",
        "**0.45**\n",
        "0.55\n",
        "0.65\n",
        "\n",
        "Answer: **0.45**"
      ],
      "metadata": {
        "id": "FRB8bOcAU1oA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from rouge import Rouge\n",
        "\n",
        "rouge = Rouge()\n",
        "\n",
        "r = df.iloc[10]\n",
        "answer_llm = r['answer_llm']\n",
        "answer_orig = r['answer_orig']\n",
        "\n",
        "scores = rouge.get_scores(answer_llm, answer_orig)[0]\n",
        "\n",
        "rouge_1_f = scores['rouge-1']['f']\n",
        "rouge_2_f = scores['rouge-2']['f']\n",
        "rouge_l_f = scores['rouge-l']['f']\n",
        "\n",
        "average_f_score = (rouge_1_f + rouge_2_f + rouge_l_f) / 3\n",
        "\n",
        "print(f\"Rouge-1 F-score: {rouge_1_f}\")\n",
        "print(f\"Rouge-2 F-score: {rouge_2_f}\")\n",
        "print(f\"Rouge-L F-score: {rouge_l_f}\")\n",
        "print(f\"Average F-score: {average_f_score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJ5O1orl3Ojx",
        "outputId": "c255b129-a345-40f3-dce7-3fddb5435f34"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rouge-1 F-score: 0.45454544954545456\n",
            "Rouge-2 F-score: 0.21621621121621637\n",
            "Rouge-L F-score: 0.393939388939394\n",
            "Average F-score: 0.35490034990035496\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Average F-score between rouge-1, rouge-2 and rouge-L for the same record from Q4 task\n",
        "\n",
        "**0.35**\n",
        "0.45\n",
        "0.55\n",
        "0.65"
      ],
      "metadata": {
        "id": "WiE_pdAAVBhe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rouge_scorer = Rouge()\n",
        "\n",
        "\n",
        "rouge_1_f = []\n",
        "rouge_2_f = []\n",
        "rouge_l_f = []\n",
        "\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "    scores = rouge_scorer.get_scores(row['answer_llm'], row['answer_orig'])[0]\n",
        "    rouge_1_f.append(scores['rouge-1']['f'])\n",
        "    rouge_2_f.append(scores['rouge-2']['f'])\n",
        "    rouge_l_f.append(scores['rouge-l']['f'])\n",
        "\n",
        "\n",
        "rouge_scores_df = pd.DataFrame({\n",
        "    'rouge-1_f': rouge_1_f,\n",
        "    'rouge-2_f': rouge_2_f,\n",
        "    'rouge-l_f': rouge_l_f\n",
        "})\n",
        "\n",
        "\n",
        "average_rouge_2 = rouge_scores_df['rouge-2_f'].mean()\n",
        "\n",
        "\n",
        "print(f\"The average ROUGE-2 score across all records is: {average_rouge_2}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vtZovFkm3i3f",
        "outputId": "80ad37aa-23fd-4e61-f0bd-436e6421d88a"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The average ROUGE-2 score across all records is: 0.20696501983423318\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "the score for all the records and create a dataframe from them.\n",
        "\n",
        "What's the average rouge_2 across all the records?\n",
        "\n",
        "0.10\n",
        "**0.20**\n",
        "0.30\n",
        "0.40"
      ],
      "metadata": {
        "id": "vVnQqNO3VSTe"
      }
    }
  ]
}